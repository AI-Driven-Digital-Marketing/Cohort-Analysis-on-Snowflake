{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84340ea3",
   "metadata": {},
   "source": [
    "# Cohort Analysis\n",
    "This notebook includes EDA, cohort analysis calculation.    \n",
    "Snowpark session Documentation : https://docs.snowflake.com/ko/developer-guide/snowpark/reference/python/session.html    \n",
    "Python Documentation: https://docs.snowflake.com/en/developer-guide/snowpark/python/index    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885bbe2",
   "metadata": {},
   "source": [
    "**examples**\n",
    "Github example:https://github.com/Snowflake-Labs/snowpark-python-demos/tree/main/Advertising-Spend-ROI-Prediction    \n",
    "Jupyter notebook example: https://github.com/Snowflake-Labs/snowpark-python-demos/blob/main/Advertising-Spend-ROI-Prediction/Snowpark_For_Python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f9cc5",
   "metadata": {},
   "source": [
    "#### Connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d7fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit,count\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f16a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : ESTPEGION\n",
      "Role                        : ACCOUNTADMIN\n",
      "Database                    : KPMG\n",
      "Schema                      : PUBLIC\n",
      "Warehouse                   : COMPUTE_WH\n",
      "Snowflake version           : 7.6.2\n",
      "Snowpark for Python version : 1.1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(snowflake_environment[0][1]))\n",
    "print('Database                    : {}'.format(snowflake_environment[0][2]))\n",
    "print('Schema                      : {}'.format(snowflake_environment[0][3]))\n",
    "print('Warehouse                   : {}'.format(snowflake_environment[0][5]))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][4]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c22814",
   "metadata": {},
   "source": [
    "#### List all tables in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a2200c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "|\"TABLE_NAME\"     |\n",
      "-------------------\n",
      "|CUSTOMERADDRESS  |\n",
      "|FOOD             |\n",
      "|TRANSACTIONS     |\n",
      "|DEMOGRAPHIC      |\n",
      "|NEWCUSTOMER      |\n",
      "|TABLES           |\n",
      "|COLUMNS          |\n",
      "|SCHEMATA         |\n",
      "|SEQUENCES        |\n",
      "|VIEWS            |\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql('select TABLE_NAME from information_schema.tables').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba122a4",
   "metadata": {},
   "source": [
    "#### Query table from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4253cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 14:18:03.064 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM TRANSACTIONS LIMIT 10]\n",
      "2023-02-22 14:18:03.159 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"TRANSACTION_ID\"  |\"PRODUCT_ID\"  |\"CUSTOMER_ID\"  |\"TRANSACTION_DATE\"   |\"ONLINE_ORDER\"  |\"ORDER_STATUS\"  |\"BRAND\"         |\"PRODUCT_LINE\"  |\"PRODUCT_CLASS\"  |\"PRODUCT_SIZE\"  |\"LIST_PRICE\"  |\"STANDARD_COST\"  |\"PRODUCT_FIRST_SOLD_DATE\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1                 |2             |2950           |2017-02-25 00:00:00  |0.0             |Approved        |Solex           |Standard        |medium           |medium          |71.49         |53.62            |41245.0                    |\n",
      "|2                 |3             |3120           |2017-05-21 00:00:00  |1.0             |Approved        |Trek Bicycles   |Standard        |medium           |large           |2091.47       |388.92           |41701.0                    |\n",
      "|3                 |37            |402            |2017-10-16 00:00:00  |0.0             |Approved        |OHM Cycles      |Standard        |low              |medium          |1793.43       |248.82           |36361.0                    |\n",
      "|4                 |88            |3135           |2017-08-31 00:00:00  |0.0             |Approved        |Norco Bicycles  |Standard        |medium           |medium          |1198.46       |381.1            |36145.0                    |\n",
      "|5                 |78            |787            |2017-10-01 00:00:00  |1.0             |Approved        |Giant Bicycles  |Standard        |medium           |large           |1765.3        |709.48           |42226.0                    |\n",
      "|6                 |25            |2339           |2017-03-08 00:00:00  |1.0             |Approved        |Giant Bicycles  |Road            |medium           |medium          |1538.99       |829.65           |39031.0                    |\n",
      "|7                 |22            |1542           |2017-04-21 00:00:00  |1.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |60.34         |45.26            |34165.0                    |\n",
      "|8                 |15            |2459           |2017-07-15 00:00:00  |0.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |1292.84       |13.44            |39915.0                    |\n",
      "|9                 |67            |1305           |2017-08-10 00:00:00  |0.0             |Approved        |Solex           |Standard        |medium           |large           |1071.23       |380.74           |33455.0                    |\n",
      "|10                |12            |3262           |2017-08-30 00:00:00  |1.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |1231.15       |161.6            |38216.0                    |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_spend = session.table('TRANSACTIONS')\n",
    "snow_df_spend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1380910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "|\"COUNT(1)\"  |\n",
      "--------------\n",
      "|20000       |\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validate row number\n",
    "snow_df_spend.select(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53f10c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import streamlit as st\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit,count\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import logging \n",
    "\n",
    "# The code below is for the title and logo for this page.\n",
    "st.set_page_config(page_title=\"Cohort Analysis on the Bikes dataset\", page_icon=\"🚲\")\n",
    "bg_image = '''\n",
    "<style>\n",
    "[data-testid=\"stAppViewContainer\"]{\n",
    "background-image: url(https://lp-cms-production.imgix.net/2022-01/GettyRF_475680439.jpg?auto=format&q=75&w=1920);\n",
    "backgroud-size:cover;\n",
    "}\n",
    "</style>\n",
    "'''\n",
    "#st.markdown(bg_image, unsafe_allow_html=True)\n",
    "#st.set_page_config(layout=\"wide\")\n",
    "st.sidebar.markdown(\"# Bike Cohort Analysis\")\n",
    "st.image(\n",
    "    \"bike.png\",\n",
    "    width  = 160\n",
    "    #use_column_width = True,\n",
    ")\n",
    "\n",
    "st.title(\"Cohort Analysis → `Bikes` dataset\")\n",
    "\n",
    "st.write(\"\")\n",
    "\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "\n",
    "    This demo is inspired by this [Cohort Analysis Tutorial](https://github.com/maladeep/cohort-retention-rate-analysis-in-python).\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "with st.expander(\"About this app\"):\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "\n",
    "    This dataset comes from the hypothetical KPMG.\n",
    "\n",
    "    Each row in the dataset contains information about an individual bike purchase:\n",
    "\n",
    "    - Who bought it\n",
    "    - How much they paid\n",
    "    - The bike's `brand` and `product line`\n",
    "    - Its `class` and `size`\n",
    "    - What day the purchase happened\n",
    "    - The day the product was first sold\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "    The underlying code groups those purchases into cohorts and calculates the `retention rate` (split by month) so that one can answer the question:\n",
    "\n",
    "    *if I'm making monthly changes to my store to get people to come back and buy more bikes, are those changes working?\"*\n",
    "\n",
    "    These cohorts are then visualized and interpreted through a heatmap [powered by Plotly](https://plotly.com/python/).\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "# A function that will parse the date Time based cohort:  1 day of month\n",
    "def get_month(x):\n",
    "    return dt.datetime(x.year, x.month, 1)\n",
    "\n",
    "@st.cache_resource\n",
    "def connect2snowflake():\n",
    "    # set logger\n",
    "    logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    # Create Snowflake Session object\n",
    "    connection_parameters = json.load(open('connection.json'))\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "\n",
    "    snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "    snowpark_version = VERSION\n",
    "    return session\n",
    "session = connect2snowflake()\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "\n",
    "    # Load data\n",
    "    transaction_df = pd.DataFrame(session.table('TRANSACTIONS').collect())\n",
    "    #transaction_df = session.sql('select * from TRANSACTIONS').toPandas()\n",
    "    transaction_df.columns = [x.lower() for x in transaction_df.columns]\n",
    "\n",
    "\n",
    "    # Process data\n",
    "    transaction_df = transaction_df.replace(\" \", np.NaN)\n",
    "    transaction_df = transaction_df.fillna(transaction_df.mean())\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].apply(\n",
    "        get_month\n",
    "    )\n",
    "    transaction_df[\"TransactionYear\"] = transaction_df[\"transaction_date\"].dt.year\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].dt.month\n",
    "    for col in transaction_df.columns:\n",
    "        if transaction_df[col].dtype == \"object\":\n",
    "            transaction_df[col] = transaction_df[col].fillna(\n",
    "                transaction_df[col].value_counts().index[0]\n",
    "            )\n",
    "\n",
    "    # Create transaction_date column based on month and store in TransactionMonth\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].apply(\n",
    "        get_month\n",
    "    )\n",
    "    # Grouping by customer_id and select the InvoiceMonth value\n",
    "    grouping = transaction_df.groupby(\"customer_id\")[\"TransactionMonth\"]\n",
    "    # Assigning a minimum InvoiceMonth value to the dataset\n",
    "    transaction_df[\"CohortMonth\"] = grouping.transform(\"min\")\n",
    "\n",
    "    return transaction_df\n",
    "\n",
    "\n",
    "transaction_df = load_data()\n",
    "\n",
    "with st.expander(\"Show the `Bikes` dataframe\"):\n",
    "    st.write(transaction_df)\n",
    "\n",
    "\n",
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "\n",
    "\n",
    "# Getting the integers for date parts from the `InvoiceDay` column\n",
    "transcation_year, transaction_month, _ = get_date_int(\n",
    "    transaction_df, \"TransactionMonth\"\n",
    ")\n",
    "# Getting the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, _ = get_date_int(transaction_df, \"CohortMonth\")\n",
    "#  Get the  difference in years\n",
    "years_diff = transcation_year - cohort_year\n",
    "# Calculate difference in months\n",
    "months_diff = transaction_month - cohort_month\n",
    "\n",
    "# Extract the difference in months from all previous values \"+1\" in addeded at the end so that first month is marked as 1 instead of 0 for easier interpretation. \"\"\"\n",
    "transaction_df[\"CohortIndex\"] = years_diff * 12 + months_diff + 1\n",
    "\n",
    "dtypes = transaction_df.dtypes.astype(str)\n",
    "# Show dtypes\n",
    "# dtypes\n",
    "\n",
    "transaction_df_new_slider_01 = transaction_df[[\"brand\", \"product_line\"]]\n",
    "new_slider_01 = [col for col in transaction_df_new_slider_01]\n",
    "\n",
    "transaction_df_new_slider_02 = transaction_df[[\"list_price\", \"standard_cost\"]]\n",
    "new_slider_02 = [col for col in transaction_df_new_slider_02]\n",
    "\n",
    "st.write(\"\")\n",
    "\n",
    "cole, col1, cole, col2, cole = st.columns([0.1, 1, 0.05, 1, 0.1])\n",
    "\n",
    "with col1:\n",
    "\n",
    "    MetricSlider01 = st.selectbox(\"Pick your 1st metric\", new_slider_01)\n",
    "\n",
    "    MetricSlider02 = st.selectbox(\"Pick your 2nd metric\", new_slider_02, index=1)\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "with col2:\n",
    "\n",
    "    if MetricSlider01 == \"brand\":\n",
    "        # col_one_list = transaction_df_new[\"brand\"].tolist()\n",
    "        col_one_list = transaction_df_new_slider_01[\"brand\"].drop_duplicates().tolist()\n",
    "        multiselect = st.multiselect(\n",
    "            \"Select the value(s)\", col_one_list, [\"Solex\", \"Trek Bicycles\"]\n",
    "        )\n",
    "        transaction_df = transaction_df[transaction_df[\"brand\"].isin(multiselect)]\n",
    "\n",
    "    elif MetricSlider01 == \"product_line\":\n",
    "        col_one_list = (\n",
    "            transaction_df_new_slider_01[\"product_line\"].drop_duplicates().tolist()\n",
    "        )\n",
    "        multiselect = st.multiselect(\n",
    "            \"Select the value(s)\", col_one_list, [\"Standard\", \"Road\"]\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"product_line\"].isin(multiselect)\n",
    "        ]\n",
    "\n",
    "    if MetricSlider02 == \"list_price\":\n",
    "        list_price_slider = st.slider(\n",
    "            \"List price (in $)\", step=500, min_value=12, max_value=2091\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"list_price\"] > list_price_slider\n",
    "        ]\n",
    "\n",
    "    elif MetricSlider02 == \"standard_cost\":\n",
    "        standard_cost_slider = st.slider(\n",
    "            \"Standard cost (in $)\", step=500, min_value=7, max_value=1759\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"list_price\"] > standard_cost_slider\n",
    "        ]\n",
    "\n",
    "try:\n",
    "\n",
    "    # Counting daily active user from each chort\n",
    "    grouping = transaction_df.groupby([\"CohortMonth\", \"CohortIndex\"])\n",
    "    # Counting number of unique customer Id's falling in each group of CohortMonth and CohortIndex\n",
    "    cohort_data = grouping[\"customer_id\"].apply(pd.Series.nunique)\n",
    "    cohort_data = cohort_data.reset_index()\n",
    "    # Assigning column names to the dataframe created above\n",
    "    cohort_counts = cohort_data.pivot(\n",
    "        index=\"CohortMonth\", columns=\"CohortIndex\", values=\"customer_id\"\n",
    "    )\n",
    "\n",
    "    cohort_sizes = cohort_counts.iloc[:, 0]\n",
    "    retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "    # Coverting the retention rate into percentage and Rounding off.\n",
    "    retention = retention.round(3) * 100\n",
    "    retention.index = retention.index.strftime(\"%Y-%m\")\n",
    "\n",
    "    # Plotting the retention rate\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_heatmap(\n",
    "        # x=retention.columns, y=retention.index, z=retention, colorscale=\"cividis\"\n",
    "        x=retention.columns,\n",
    "        y=retention.index,\n",
    "        z=retention,\n",
    "        # Best\n",
    "        # colorscale=\"Aggrnyl\",\n",
    "        colorscale=\"Bluyl\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title_text=\"Monthly cohorts showing retention rates\", title_x=0.2)\n",
    "    fig.layout.xaxis.title = \"Cohort Group\"\n",
    "    fig.layout.yaxis.title = \"Cohort Period\"\n",
    "    fig[\"layout\"][\"title\"][\"font\"] = dict(size=25)\n",
    "    fig.layout.width = 750\n",
    "    fig.layout.height = 750\n",
    "    fig.layout.xaxis.tickvals = retention.columns\n",
    "    fig.layout.yaxis.tickvals = retention.index\n",
    "    fig.layout.plot_bgcolor = \"#efefef\"  # Set the background color to white\n",
    "    fig.layout.margin.b = 100\n",
    "    fig\n",
    "\n",
    "except IndexError:\n",
    "    st.warning(\"This is throwing an exception, bear with us!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e324c2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERID</th>\n",
       "      <th>ORDERDATE</th>\n",
       "      <th>USEID</th>\n",
       "      <th>TOTALCHARGES</th>\n",
       "      <th>COMMONID</th>\n",
       "      <th>PUPID</th>\n",
       "      <th>PICKUPDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>2009/1/11</td>\n",
       "      <td>47</td>\n",
       "      <td>50.67</td>\n",
       "      <td>TRQKD</td>\n",
       "      <td>2</td>\n",
       "      <td>2009/1/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>2009/1/20</td>\n",
       "      <td>47</td>\n",
       "      <td>26.60</td>\n",
       "      <td>4HH2S</td>\n",
       "      <td>3</td>\n",
       "      <td>2009/1/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294</td>\n",
       "      <td>2009/2/3</td>\n",
       "      <td>47</td>\n",
       "      <td>38.71</td>\n",
       "      <td>3TRDC</td>\n",
       "      <td>2</td>\n",
       "      <td>2009/2/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>2009/2/6</td>\n",
       "      <td>47</td>\n",
       "      <td>53.38</td>\n",
       "      <td>NGAZJ</td>\n",
       "      <td>2</td>\n",
       "      <td>2009/2/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>2009/2/6</td>\n",
       "      <td>47</td>\n",
       "      <td>14.28</td>\n",
       "      <td>FFYHD</td>\n",
       "      <td>2</td>\n",
       "      <td>2009/2/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>3220</td>\n",
       "      <td>2010/3/8</td>\n",
       "      <td>393616</td>\n",
       "      <td>60.02</td>\n",
       "      <td>AWNXG</td>\n",
       "      <td>15</td>\n",
       "      <td>2010/3/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>3192</td>\n",
       "      <td>2010/3/7</td>\n",
       "      <td>394290</td>\n",
       "      <td>45.43</td>\n",
       "      <td>AKGQT</td>\n",
       "      <td>12</td>\n",
       "      <td>2010/3/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>3193</td>\n",
       "      <td>2010/3/7</td>\n",
       "      <td>394346</td>\n",
       "      <td>14.21</td>\n",
       "      <td>2B47R</td>\n",
       "      <td>15</td>\n",
       "      <td>2010/3/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>3207</td>\n",
       "      <td>2010/3/8</td>\n",
       "      <td>395039</td>\n",
       "      <td>34.62</td>\n",
       "      <td>H6E23</td>\n",
       "      <td>4</td>\n",
       "      <td>2010/3/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>3231</td>\n",
       "      <td>2010/3/8</td>\n",
       "      <td>396551</td>\n",
       "      <td>127.28</td>\n",
       "      <td>9SBZ8</td>\n",
       "      <td>3</td>\n",
       "      <td>2010/3/8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORDERID  ORDERDATE   USEID  TOTALCHARGES COMMONID  PUPID PICKUPDATE\n",
       "0         262  2009/1/11      47         50.67    TRQKD      2  2009/1/11\n",
       "1         278  2009/1/20      47         26.60    4HH2S      3  2009/1/20\n",
       "2         294   2009/2/3      47         38.71    3TRDC      2   2009/2/3\n",
       "3         301   2009/2/6      47         53.38    NGAZJ      2   2009/2/6\n",
       "4         302   2009/2/6      47         14.28    FFYHD      2   2009/2/6\n",
       "...       ...        ...     ...           ...      ...    ...        ...\n",
       "2886     3220   2010/3/8  393616         60.02    AWNXG     15   2010/3/8\n",
       "2887     3192   2010/3/7  394290         45.43    AKGQT     12   2010/3/7\n",
       "2888     3193   2010/3/7  394346         14.21    2B47R     15   2010/3/7\n",
       "2889     3207   2010/3/8  395039         34.62    H6E23      4   2010/3/8\n",
       "2890     3231   2010/3/8  396551        127.28    9SBZ8      3   2010/3/8\n",
       "\n",
       "[2891 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_df = pd.DataFrame(session.table('FOOD').collect())\n",
    "food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fac4511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORDERID           int64\n",
       "ORDERDATE        object\n",
       "USEID             int64\n",
       "TOTALCHARGES    float64\n",
       "COMMONID         object\n",
       "PUPID             int64\n",
       "PICKUPDATE       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dbf1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pages/Food_Cohort_Analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/Food_Cohort_Analysis.py\n",
    "import streamlit as st\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit,count\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import logging \n",
    "\n",
    "# The code below is for the title and logo for this page.\n",
    "st.set_page_config(page_title=\"Cohort Analysis on the Food dataset\", page_icon=\"🍔\")\n",
    "\n",
    "st.image(\n",
    "    \"Food.jpg\",\n",
    "    width=400,\n",
    ")\n",
    "\n",
    "st.title(\"Cohort Analysis → `Food` dataset\")\n",
    "\n",
    "st.write(\"\")\n",
    "\n",
    "\n",
    "\n",
    "with st.expander(\"About this app\"):\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "\n",
    "    This dataset comes from the hypothetical KPMG.\n",
    "\n",
    "    Each row in the dataset contains information about an individual bike purchase:\n",
    "\n",
    "    - Who bought it\n",
    "    - How much they paid\n",
    "    - The bike's `brand` and `product line`\n",
    "    - Its `class` and `size`\n",
    "    - What day the purchase happened\n",
    "    - The day the product was first sold\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "    The underlying code groups those purchases into cohorts and calculates the `retention rate` (split by month) so that one can answer the question:\n",
    "\n",
    "    *if I'm making monthly changes to my store to get people to come back and buy more bikes, are those changes working?\"*\n",
    "\n",
    "    These cohorts are then visualized and interpreted through a heatmap [powered by Plotly](https://plotly.com/python/).\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "# A function that will parse the date Time based cohort:  1 day of month\n",
    "def get_month(x):\n",
    "    return dt.datetime(x.year, x.month, 1)\n",
    "\n",
    "@st.cache_resource\n",
    "def connect2snowflake():\n",
    "    # set logger\n",
    "    logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    # Create Snowflake Session object\n",
    "    connection_parameters = json.load(open('connection.json'))\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "\n",
    "    snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "    snowpark_version = VERSION\n",
    "    return session\n",
    "session = connect2snowflake()\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "\n",
    "    # Load data\n",
    "    food_df = pd.DataFrame(session.table('FOOD').collect())\n",
    "    food_df.columns = [x.lower() for x in food_df.columns]\n",
    "    # write our codes here -- INFO Teams!\n",
    "\n",
    "    return food_df\n",
    "\n",
    "\n",
    "food_df = load_data()\n",
    "food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a558626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: SNPark\n",
    "dependencies:\n",
    "  - snowflake-snowpark-python\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - plotly\n",
    "  - matplotlib\n",
    "  - seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f02d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark",
   "language": "python",
   "name": "snowpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
