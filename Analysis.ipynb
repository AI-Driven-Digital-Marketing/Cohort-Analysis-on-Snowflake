{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84340ea3",
   "metadata": {},
   "source": [
    "# Cohort Analysis\n",
    "This notebook includes EDA, cohort analysis calculation.    \n",
    "Snowpark session Documentation : https://docs.snowflake.com/ko/developer-guide/snowpark/reference/python/session.html    \n",
    "Python Documentation: https://docs.snowflake.com/en/developer-guide/snowpark/python/index    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42bb5d",
   "metadata": {},
   "source": [
    "**examples**\n",
    "Github example:https://github.com/Snowflake-Labs/snowpark-python-demos/tree/main/Advertising-Spend-ROI-Prediction    \n",
    "Jupyter notebook example: https://github.com/Snowflake-Labs/snowpark-python-demos/blob/main/Advertising-Spend-ROI-Prediction/Snowpark_For_Python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f9cc5",
   "metadata": {},
   "source": [
    "#### Connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d7fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit,count\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f16a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 14:17:18.093 INFO    snowflake.connector.connection: Snowflake Connector for Python Version: 2.7.12, Python Version: 3.8.16, Platform: Windows-10-10.0.22000-SP0\n",
      "2023-02-22 14:17:18.094 INFO    snowflake.connector.connection: This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 14:17:18.094 INFO    snowflake.connector.connection: Setting use_openssl_only mode to False\n",
      "2023-02-22 14:17:19.070 INFO    snowflake.connector.cursor: query: [alter session set PYTHON_SNOWPARK_USE_SQL_SIMPLIFIER = True]\n",
      "2023-02-22 14:17:19.151 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-22 14:17:19.156 INFO    snowflake.connector.cursor: query: [select current_user(), current_role(), current_database(), current_schema(), cur...]\n",
      "2023-02-22 14:17:19.240 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : ESTPEGION\n",
      "Role                        : ACCOUNTADMIN\n",
      "Database                    : KPMG\n",
      "Schema                      : PUBLIC\n",
      "Warehouse                   : COMPUTE_WH\n",
      "Snowflake version           : 7.6.2\n",
      "Snowpark for Python version : 1.1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(snowflake_environment[0][1]))\n",
    "print('Database                    : {}'.format(snowflake_environment[0][2]))\n",
    "print('Schema                      : {}'.format(snowflake_environment[0][3]))\n",
    "print('Warehouse                   : {}'.format(snowflake_environment[0][5]))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][4]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c22814",
   "metadata": {},
   "source": [
    "#### List all tables in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2200c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 14:17:46.823 INFO    snowflake.connector.cursor: query: [select TABLE_NAME from information_schema.tables]\n",
      "2023-02-22 14:17:46.969 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-22 14:17:46.971 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM (select TABLE_NAME from information_schema.tables) LIMIT 10]\n",
      "2023-02-22 14:17:47.606 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "|\"TABLE_NAME\"     |\n",
      "-------------------\n",
      "|CUSTOMERADDRESS  |\n",
      "|TRANSACTIONS     |\n",
      "|DEMOGRAPHIC      |\n",
      "|NEWCUSTOMER      |\n",
      "|FOOD             |\n",
      "|TABLES           |\n",
      "|COLUMNS          |\n",
      "|SCHEMATA         |\n",
      "|SEQUENCES        |\n",
      "|VIEWS            |\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql('select TABLE_NAME from information_schema.tables').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba122a4",
   "metadata": {},
   "source": [
    "#### Query table from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4253cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 14:18:03.064 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM TRANSACTIONS LIMIT 10]\n",
      "2023-02-22 14:18:03.159 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"TRANSACTION_ID\"  |\"PRODUCT_ID\"  |\"CUSTOMER_ID\"  |\"TRANSACTION_DATE\"   |\"ONLINE_ORDER\"  |\"ORDER_STATUS\"  |\"BRAND\"         |\"PRODUCT_LINE\"  |\"PRODUCT_CLASS\"  |\"PRODUCT_SIZE\"  |\"LIST_PRICE\"  |\"STANDARD_COST\"  |\"PRODUCT_FIRST_SOLD_DATE\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1                 |2             |2950           |2017-02-25 00:00:00  |0.0             |Approved        |Solex           |Standard        |medium           |medium          |71.49         |53.62            |41245.0                    |\n",
      "|2                 |3             |3120           |2017-05-21 00:00:00  |1.0             |Approved        |Trek Bicycles   |Standard        |medium           |large           |2091.47       |388.92           |41701.0                    |\n",
      "|3                 |37            |402            |2017-10-16 00:00:00  |0.0             |Approved        |OHM Cycles      |Standard        |low              |medium          |1793.43       |248.82           |36361.0                    |\n",
      "|4                 |88            |3135           |2017-08-31 00:00:00  |0.0             |Approved        |Norco Bicycles  |Standard        |medium           |medium          |1198.46       |381.1            |36145.0                    |\n",
      "|5                 |78            |787            |2017-10-01 00:00:00  |1.0             |Approved        |Giant Bicycles  |Standard        |medium           |large           |1765.3        |709.48           |42226.0                    |\n",
      "|6                 |25            |2339           |2017-03-08 00:00:00  |1.0             |Approved        |Giant Bicycles  |Road            |medium           |medium          |1538.99       |829.65           |39031.0                    |\n",
      "|7                 |22            |1542           |2017-04-21 00:00:00  |1.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |60.34         |45.26            |34165.0                    |\n",
      "|8                 |15            |2459           |2017-07-15 00:00:00  |0.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |1292.84       |13.44            |39915.0                    |\n",
      "|9                 |67            |1305           |2017-08-10 00:00:00  |0.0             |Approved        |Solex           |Standard        |medium           |large           |1071.23       |380.74           |33455.0                    |\n",
      "|10                |12            |3262           |2017-08-30 00:00:00  |1.0             |Approved        |WeareA2B        |Standard        |medium           |medium          |1231.15       |161.6            |38216.0                    |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_spend = session.table('TRANSACTIONS')\n",
    "snow_df_spend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1380910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "|\"COUNT(1)\"  |\n",
      "--------------\n",
      "|20000       |\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validate row number\n",
    "snow_df_spend.select(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a90a64fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import streamlit as st\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit,count\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import logging \n",
    "\n",
    "# The code below is for the title and logo for this page.\n",
    "st.set_page_config(page_title=\"Cohort Analysis on the Bikes dataset\", page_icon=\"🚲\")\n",
    "\n",
    "st.image(\n",
    "    \"bike.png\",\n",
    "    width=160,\n",
    ")\n",
    "\n",
    "st.title(\"Cohort Analysis → `Bikes` dataset\")\n",
    "\n",
    "st.write(\"\")\n",
    "\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "\n",
    "    This demo is inspired by this [Cohort Analysis Tutorial](https://github.com/maladeep/cohort-retention-rate-analysis-in-python).\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "with st.expander(\"About this app\"):\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "\n",
    "    This dataset comes from the hypothetical `Sprocket Central Pty Ltd`, a medium size bikes & cycling accessories organisation.\n",
    "\n",
    "    The data spans from `January 1, 2017` to `December 31, 2017` and is available in CSV format (downloadable [here](https://www.kaggle.com/datasets/archit9406/customer-transaction-dataset)).\n",
    "\n",
    "    Each row in the dataset contains information about an individual bike purchase:\n",
    "\n",
    "    - Who bought it\n",
    "    - How much they paid\n",
    "    - The bike's `brand` and `product line`\n",
    "    - Its `class` and `size`\n",
    "    - What day the purchase happened\n",
    "    - The day the product was first sold\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "    The underlying code groups those purchases into cohorts and calculates the `retention rate` (split by month) so that one can answer the question:\n",
    "\n",
    "    *if I'm making monthly changes to my store to get people to come back and buy more bikes, are those changes working?\"*\n",
    "\n",
    "    These cohorts are then visualized and interpreted through a heatmap [powered by Plotly](https://plotly.com/python/).\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "# A function that will parse the date Time based cohort:  1 day of month\n",
    "def get_month(x):\n",
    "    return dt.datetime(x.year, x.month, 1)\n",
    "\n",
    "@st.cache_resource\n",
    "def connect2snowflake():\n",
    "    # set logger\n",
    "    logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    # Create Snowflake Session object\n",
    "    connection_parameters = json.load(open('connection.json'))\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "\n",
    "    snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "    snowpark_version = VERSION\n",
    "    return session\n",
    "session = connect2snowflake()\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "\n",
    "    # Load data\n",
    "    #transaction_df = pd.read_excel(\"datasets/transaction.xlsx\")\n",
    "    transaction_df = session.table('TRANSACTIONS').to_pandas()\n",
    "    transaction_df.columns = [x.lower() for x in transaction_df.columns]\n",
    "\n",
    "\n",
    "    # Process data\n",
    "    transaction_df = transaction_df.replace(\" \", np.NaN)\n",
    "    transaction_df = transaction_df.fillna(transaction_df.mean())\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].apply(\n",
    "        get_month\n",
    "    )\n",
    "    transaction_df[\"TransactionYear\"] = transaction_df[\"transaction_date\"].dt.year\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].dt.month\n",
    "    for col in transaction_df.columns:\n",
    "        if transaction_df[col].dtype == \"object\":\n",
    "            transaction_df[col] = transaction_df[col].fillna(\n",
    "                transaction_df[col].value_counts().index[0]\n",
    "            )\n",
    "\n",
    "    # Create transaction_date column based on month and store in TransactionMonth\n",
    "    transaction_df[\"TransactionMonth\"] = transaction_df[\"transaction_date\"].apply(\n",
    "        get_month\n",
    "    )\n",
    "    # Grouping by customer_id and select the InvoiceMonth value\n",
    "    grouping = transaction_df.groupby(\"customer_id\")[\"TransactionMonth\"]\n",
    "    # Assigning a minimum InvoiceMonth value to the dataset\n",
    "    transaction_df[\"CohortMonth\"] = grouping.transform(\"min\")\n",
    "\n",
    "    return transaction_df\n",
    "\n",
    "\n",
    "transaction_df = load_data()\n",
    "\n",
    "with st.expander(\"Show the `Bikes` dataframe\"):\n",
    "    st.write(transaction_df)\n",
    "\n",
    "\n",
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "\n",
    "\n",
    "# Getting the integers for date parts from the `InvoiceDay` column\n",
    "transcation_year, transaction_month, _ = get_date_int(\n",
    "    transaction_df, \"TransactionMonth\"\n",
    ")\n",
    "# Getting the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, _ = get_date_int(transaction_df, \"CohortMonth\")\n",
    "#  Get the  difference in years\n",
    "years_diff = transcation_year - cohort_year\n",
    "# Calculate difference in months\n",
    "months_diff = transaction_month - cohort_month\n",
    "\n",
    "# Extract the difference in months from all previous values \"+1\" in addeded at the end so that first month is marked as 1 instead of 0 for easier interpretation. \"\"\"\n",
    "transaction_df[\"CohortIndex\"] = years_diff * 12 + months_diff + 1\n",
    "\n",
    "dtypes = transaction_df.dtypes.astype(str)\n",
    "# Show dtypes\n",
    "# dtypes\n",
    "\n",
    "transaction_df_new_slider_01 = transaction_df[[\"brand\", \"product_line\"]]\n",
    "new_slider_01 = [col for col in transaction_df_new_slider_01]\n",
    "\n",
    "transaction_df_new_slider_02 = transaction_df[[\"list_price\", \"standard_cost\"]]\n",
    "new_slider_02 = [col for col in transaction_df_new_slider_02]\n",
    "\n",
    "st.write(\"\")\n",
    "\n",
    "cole, col1, cole, col2, cole = st.columns([0.1, 1, 0.05, 1, 0.1])\n",
    "\n",
    "with col1:\n",
    "\n",
    "    MetricSlider01 = st.selectbox(\"Pick your 1st metric\", new_slider_01)\n",
    "\n",
    "    MetricSlider02 = st.selectbox(\"Pick your 2nd metric\", new_slider_02, index=1)\n",
    "\n",
    "    st.write(\"\")\n",
    "\n",
    "with col2:\n",
    "\n",
    "    if MetricSlider01 == \"brand\":\n",
    "        # col_one_list = transaction_df_new[\"brand\"].tolist()\n",
    "        col_one_list = transaction_df_new_slider_01[\"brand\"].drop_duplicates().tolist()\n",
    "        multiselect = st.multiselect(\n",
    "            \"Select the value(s)\", col_one_list, [\"Solex\", \"Trek Bicycles\"]\n",
    "        )\n",
    "        transaction_df = transaction_df[transaction_df[\"brand\"].isin(multiselect)]\n",
    "\n",
    "    elif MetricSlider01 == \"product_line\":\n",
    "        col_one_list = (\n",
    "            transaction_df_new_slider_01[\"product_line\"].drop_duplicates().tolist()\n",
    "        )\n",
    "        multiselect = st.multiselect(\n",
    "            \"Select the value(s)\", col_one_list, [\"Standard\", \"Road\"]\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"product_line\"].isin(multiselect)\n",
    "        ]\n",
    "\n",
    "    if MetricSlider02 == \"list_price\":\n",
    "        list_price_slider = st.slider(\n",
    "            \"List price (in $)\", step=500, min_value=12, max_value=2091\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"list_price\"] > list_price_slider\n",
    "        ]\n",
    "\n",
    "    elif MetricSlider02 == \"standard_cost\":\n",
    "        standard_cost_slider = st.slider(\n",
    "            \"Standard cost (in $)\", step=500, min_value=7, max_value=1759\n",
    "        )\n",
    "        transaction_df = transaction_df[\n",
    "            transaction_df[\"list_price\"] > standard_cost_slider\n",
    "        ]\n",
    "\n",
    "try:\n",
    "\n",
    "    # Counting daily active user from each chort\n",
    "    grouping = transaction_df.groupby([\"CohortMonth\", \"CohortIndex\"])\n",
    "    # Counting number of unique customer Id's falling in each group of CohortMonth and CohortIndex\n",
    "    cohort_data = grouping[\"customer_id\"].apply(pd.Series.nunique)\n",
    "    cohort_data = cohort_data.reset_index()\n",
    "    # Assigning column names to the dataframe created above\n",
    "    cohort_counts = cohort_data.pivot(\n",
    "        index=\"CohortMonth\", columns=\"CohortIndex\", values=\"customer_id\"\n",
    "    )\n",
    "\n",
    "    cohort_sizes = cohort_counts.iloc[:, 0]\n",
    "    retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "    # Coverting the retention rate into percentage and Rounding off.\n",
    "    retention = retention.round(3) * 100\n",
    "    retention.index = retention.index.strftime(\"%Y-%m\")\n",
    "\n",
    "    # Plotting the retention rate\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_heatmap(\n",
    "        # x=retention.columns, y=retention.index, z=retention, colorscale=\"cividis\"\n",
    "        x=retention.columns,\n",
    "        y=retention.index,\n",
    "        z=retention,\n",
    "        # Best\n",
    "        # colorscale=\"Aggrnyl\",\n",
    "        colorscale=\"Bluyl\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title_text=\"Monthly cohorts showing retention rates\", title_x=0.5)\n",
    "    fig.layout.xaxis.title = \"Cohort Group\"\n",
    "    fig.layout.yaxis.title = \"Cohort Period\"\n",
    "    fig[\"layout\"][\"title\"][\"font\"] = dict(size=25)\n",
    "    fig.layout.width = 750\n",
    "    fig.layout.height = 750\n",
    "    fig.layout.xaxis.tickvals = retention.columns\n",
    "    fig.layout.yaxis.tickvals = retention.index\n",
    "    fig.layout.plot_bgcolor = \"#efefef\"  # Set the background color to white\n",
    "    fig.layout.margin.b = 100\n",
    "    fig\n",
    "\n",
    "except IndexError:\n",
    "    st.warning(\"This is throwing an exception, bear with us!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55ceb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: SNPark\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - snowflake-snowpark-python\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - plotly=5.6.0\n",
    "  - matplotlib\n",
    "  - seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae1a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'streamlit' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!streamlit run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35aaf697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\zwdua\\anaconda3\\envs\\snowpark\\lib\\site-packages (5.13.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\zwdua\\anaconda3\\envs\\snowpark\\lib\\site-packages (from plotly) (8.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb684523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark",
   "language": "python",
   "name": "snowpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
